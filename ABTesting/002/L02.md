# A/B тестирование

На этом уроке: 
1.	Разберём, что такое продуктовые гипотезы и зачем они нужны.
2.	Рассмотрим структуру хорошей гипотезы.
3.	Увидим, какие подходы к поиску и генерации гипотез существуют.
4.	Узнаете, зачем и как выбирать наиболее ценные для вашего продукта гипотезы.
5.	Рассмотрим какие виды экспериментов существуют
6.	Обсудим как понять можно ли и нужно ли вам проводить А/Б-тест
7.	Посмотрим, как выглядит процесс A/B тестирования
8.	Познакомимся с кратким описанием Google Optimize и первыми шагами в нем.

## Содержание

+ [A/B тестирование](#ав-тестирование)
+ [A/B/N.. Тестирование](#abn-тестирование)
+ [Ухудшающие эксперименты](#ухудшающие-эксперименты)
+ [Область применимости А/B тестов](#область-применимости-аb-тестов)
+ [Процесс A/B тестирования](#процесс-ab-тестирования)
+ [Краткое описание Google Optimize](#краткое-описание-google-optimize)
+ [Работа на семинаре](#работа-на-семинаре)
+ [Практическое задание (ДЗ)](#практическое-задание)

[Содержание курса](/ABTesting/README.MD)

<hr>

## Какие виды экспериментов существуют
Среди самых распространенных классических методологий в продуктовом мире можно выделить 4 вида экспериментов.
+ A/B тесты
+ A/A тесты
+ A/B/../N (MVT) тесты
+ Ухудшающие эксперименты

![Введение](/ABTesting/Pictures/002_012.PNG)

## А/В тестирование

![a/b testing](/ABTesting/Pictures/002_001.png)

![Введение](/ABTesting/Pictures/002_013.PNG)

![Введение](/ABTesting/Pictures/002_014.PNG)

Между собой сравниваются два варианта (контроль и тест) чтобы определить какой из вариантов эффективнее.
+ Юзеры делятся случайным образом на две группы и берутся из одной генеральной совокупности.
+ Внешние условия должны одинаково влиять на обе группы.

Между группами должно получаться единственное различие - то изменение, которое мы тестируем.

При правильном дизайне - позволяет нам делать выводы о наличии причинно - следственной связи между внедрением новых изменений в продукте и изменением метрик.

Применяется для проверки гипотез и является одним из наиболее честных способов провалидировать продуктовые гипотезы.

### Для чего нужно?

![ПРоцесс тестирования](/ABTesting/Pictures/002_020.PNG)

Главная цель А/А-теста — показать, можно ли доверять результатам эксперимента, который будет запущен в тех же условиях, но уже с разными вариантами страницы. 

Принцип похож на A/B
+ Юзеры делятся случайным образом на две группы
+ Внешние условия должны одинаково влиять на обе группы

Но при этом продуктовых отличий между группами нет. 

Люди видят одинаковые версии продукта.

Это позволяет отловить баги в системе сплитования юзеров - поскольку если между группами будет значимое различие в метриках - оно может объясняться плохим качеством сплит-системы (отличиями в юзерах), а не продуктовым изменением.

### Пример 

Это лендинг, который тестировала команда Copyhackers в ноябре 2012 года:

![a/b testing](/ABTesting/Pictures/002_002.png)

Через 6 дней система тестирования отметила «победивший» вариант при уровне достоверности 95%. 

Ради точности эксперимент продлили на день – и достигли 99,6% точности:

![a/b testing](/ABTesting/Pictures/002_003.png)

Страница на 24% эффективнее, чем точно такая же? Результат ложноположительный. Еще через 3 дня различия исчезли:

![a/b testing](/ABTesting/Pictures/002_004.png)

Вывод: тест слишком рано вычислил победителя.

![Введение](/ABTesting/Pictures/002_015.PNG)

![Введение](/ABTesting/Pictures/002_016.PNG)

![Введение](/ABTesting/Pictures/002_017.PNG)

![Введение](/ABTesting/Pictures/002_018.PNG)

[Содержание](#содержание)

<hr>

## A/B/N.. Тестирование

[A/B/N.. Тестирование](https://www.optimizely.com/optimization-glossary/abn-testing/)

![a/b testing](/ABTesting/Pictures/002_005.png)

Между собой сравниваются более двух вариантов (первая/вторая/n группа...) чтобы определить какой из вариантов эффективнее.

То же самое что и A/B только сравнивается от 2 - можно протестировать много вариантов за схожий промежуток времени.

За преимущества проверки большего числа вариантов придется заплатить объемом трафика и в некоторых случаях точностью тестов.

Этот вид тестирования сопряжен с проблемой [множественной проверки гипотез](https://habr.com/ru/company/yandex/blog/476826/) - поговорим о ней на следующих занятиях.

![a/b/n testing](/ABTesting/Pictures/002_021.PNG)

[Содержание](#содержание)

<hr>

## Ухудшающие эксперименты

![a/b testing](/ABTesting/Pictures/002_006.jpg)

![a/b testing](/ABTesting/Pictures/002_022.PNG)

Ухудшающий эксперимент — это дешевый и довольно простой способ проверять гипотезы с помощью ухудшения кусков продукта. Сразу может возникнуть вопрос - а зачем это делать? Мы же собираемся улучшать продукт и растить его метрики, а не портить его. Все верно! Суть данного подхода состоит в том, чтобы завалидировать существование зависимостей метрик от определенных параметров продукта для дальнейшей генерации идей и гипотез. Найти способ как гарантированно ухудшить продукт довольно легко, а вот гарантированно его улучшить, к сожалению, нет - ведь иначе команды бы уже давно знали, что им делать.
Таким образом, ухудшая кусок продукта можно быстро посмотреть, а есть ли зависимость в принципе: например, влияет ли замедление сайта/приложения на ключевые метрики или нет.
Если реакция метрик есть, значит команде продукта стоит обратить внимание на целесообразность инвестиций своего времени в работу со скоростью сайта/приложения. Если нет, тестировать другие гипотезы. Довольно подробно на русском метод описан в [статье](https://gopractice.ru/ab-test/). Ограничением для данного подхода может являться, например консервативность руководства, людям необходимо правильно донести его суть.

[Содержание](#содержание)

<hr>

## Область применимости А/B тестов

![a/b testing](/ABTesting/Pictures/002_007.png)

![a/b testing](/ABTesting/Pictures/002_008.png)

У данного инструмента есть множество плюсов - например, при правильном проведении мы можем переносить выводы с выборки на генеральную совокупность, а также проверять наличие причинно-следственной связи между выкаткой новой фичи и изменением метрик продукта. 

Однако, за плюсы АБ-тестов необходимо платить: объемом трафика, затратами на разработку и временем. Перед тем, как выбрать этот инструмент для проверки гипотезы нужно проверить себя по следующим пунктам:
1. В вашем продукте уже достаточно трафика, чтобы собрать необходимое количество наблюдений для принятия решений.<br>
Молодым продуктам, которые запустились только недавно и еще не имеют большого количества юзеров, B2B продуктам - увы, этот инструмент не подойдет. Вам лучше использовать качественные методы исследования. Про расчет необходимой выборки и длительности теста - будем говорить на следующих занятиях.
2. Ожидаемый эффект от вашего изменения очень маленький/затраты на проведение теста не окупают потенциальный эффект.<br>
Чем слабее фича влияет на продукт и ваших пользователей, чем ниже ожидаемый эффект, тем больше нам нужно данных для того, чтобы это влияние зафиксировать. Перед тем как пытаться валидировать c помощью а/б теста незначительные для пользователя изменения - лучше хорошо подумать. На разработку и запуск изменения может быть потрачено много времени, человекочасов, трафика и денег. Эффект может не окупить всех затрат. Если вы не Google, Facebook и т.п., которые на своем гигантском трафике могут завалидировать даже самые микроскопические изменения метрик (например, от покраски кнопок в другой цвет:)) - лучше выбирать для данного вида тестирования только действительно сильные гипотезы. Ведь пока вы тратите время на проверку маленьких изменений - у вас могут валяться и ждать своей очереди действительно важные изменения.

[Видео для поднятия настроения](https://www.youtube.com/watch?v=UTPcFZCdSD4&feature=youtu.be) :)

3. У вас есть инфраструктура/компетенции в команде для проведения и оценки экспериментов.<br>
Многие команды неправильно проводят и оценивают эксперименты(несвоевременное время проведения теста, неправильные настройки для разных групп, тестирование нескольких гипотез одновременно). В результате раскатки 'успешных' фич их ключевые метрики могут стоять на месте или падать в результате действий команды.

Для каких изменений вы можете его применять?

## Направления для применения A/B тестов:
+ Тестирование новых фич в приложениях и нового функционала на сайтах
+ Эксперименты в оперейшнс
+ Эксперименты с дизайном
+ Тестирование алгоритмов
+ Эксперименты с ценообразованием

[Содержание](#содержание)

<hr>

## Процесс A/B тестирования

![a/b testing](/ABTesting/Pictures/002_009.png)

![ПРоцесс тестирования](/ABTesting/Pictures/002_019.PNG)

Возможный процесс:

Весь процесс можно разбить на 4-5 этапов:
1. Планирование эксперимента
    + Определяем проблему(ы)/ цели и генерируем гипотезы, формируем бэклог
    + Приоритезируем их
    + Для самых перспективных - продумываем дизайн эксперимента
2. Подготовка продуктовых изменений
3. Запуск теста 
    + Запускаем тест, сплитуя юзеров
    + Делаем мониторинги(дашборды)
4. Анализ результатов теста
5. Принятие решений

![a/b testing](/ABTesting/Pictures/002_023.PNG)

[Почитать интересную статью](https://gopractice.ru/how_to_increase_the_number_of_successful_experiments/)

[Содержание](#содержание)

<hr>

## Краткое описание Google Optimize

![a/b testing](/ABTesting/Pictures/002_010.png)

Не у всех команд есть своя самописная инфраструктура для сплитования и сбора данных - поэтому на рынке существуют различные готовые инструменты для проведения экспериментов.

Например [Optimize и Optimizely](https://insightwhale.com/google-optimize-vs-optimizely-comparing-a-b-testing-tools/)

поговорим про Optimize от гугла
В чем его плюсы:
+ Интеграция с экосистемой гугла (GA/GTM)
+ Почти No-code инструмент (можно немного сэкономить на разработчиках )

Нюансы:
+ Больше подходит для всяких UX тестов
+ Под капотом байесовские методы статистики
+ Есть платная и бесплатная версии

![a/b testing](/ABTesting/Pictures/002_011.png)

(Сравнение платной и бесплатной версий)

Для более детального ознакомления с ним можно почитать статьи:
+ [Google Optimize Guide: Do A/B Testing for Free](https://cxl.com/blog/google-optimize/)
+ [Google Optimize: как тестировать UX сайта без программиста](https://blog.click.ru/growthhacking/google-optimize-kak-testirovat-ux-sajta-bez-programmista/)

и туториалы / курсы:
+ [Optimize video tutorials](https://support.google.com/optimize/answer/9340015?hl=en)
+ [Learn Google Optimize - Beginners - Free A/B Testing Tool](https://www.udemy.com/course/learn-google-optimize-course/)

## Первые шаги (step by step)

1.	Откройте страницу https://optimize.google.com/
2.	Создайте аккаунт
3.	Нажмите ‘Начать’ (cтраница ‘Создайте проект оптимизации’)
4.	Укажите название и URL
5.	Выберите проект оптимизации, который хотите создать
6.	Создайте варианты сайта для тестирования
7.	Внесите изменения
8.	Настройте аудиторию
9.	Установите связь с Google Analytics
10.	Настройте цели
11.	Проверьте связь страницы с Google Optimize

На этом уроке мы:
+ Рассмотрели какие виды экспериментов существуют
+ Обсудили как понять можно ли и нужно ли вам проводить А/Б-тест
+ Посмотрели, как выглядит процесс A/B тестирования

На следующем занятии мы:
+ поговорим о настройках а/б тестов в веб приложениях
+ запустим и с нуля настроим а/б тест в Google Optimize

[Содержание](#содержание)

<hr>

## Работа на семинаре

### Метрики ВК
+ Кол-во пользователей в день
+ Кол-во активных пользователей в день
+ Конверсия в продление в подписку
+ Кол-во сообщений об ошибке
+ Активность на пользователя в мессенджере(сообщения в день, кол-во активных диалогов)
+ Кол-во переходов в сторонние сервисы

### Гипотеза 1:  
Если поощрять пользователей за актив связанный с вк фестом, то кол-во активных пользователей увеличится на 5% <br>
__Что делаем в каждой из групп:__
+ Контрольная группа без изменений,
+ тестовая группа: каждые 10 постов в ленте триггерный пост о активности к вк фесту<br>

__На каких пользователях тестируем:__ мало-активные пользователи<br>
__Метрики:__ Кол-во активных пользователей в день, продажа билетов на вк фест(вспомогательная)

### Гипотеза 2:  
Если сделаем “параллельный импорт” музыки и добавим зарубежные новинки, то конверсия в продление в подписку увеличится на 15%<br>
__Что делаем в каждой из групп:__
+ Контрольная группа без изменений,
+ Тестовая группа: даем пробный период с новыми песнями<br>

__На каких пользователях тестируем:__ те, у кого есть активная подписка<br>
__Метрики:__ конверсия в продление в подписку, конверсия в подписку(вспомогательная)

### Гипотеза 3:  
Если настроить тестирующую систему на основе нейросети марусягпт, то кол-во сообщений об ошибке уменьшится на 20%
__Что делаем в каждой из групп:__
+ Контрольная группа без изменений,
+ тестовая группа: запустим нейросеть на обучение по их данным

__На каких пользователях тестируем:__ на всех пользователях с мобильного приложения<br>
__Метрики:__ кол-во сообщений об ошибке

### Гипотеза 4:  

Если создать лимитированный и эксклюзивный стикерпак за активность в месенджере(кол-во сообщений >= 1000), то активность на пользователя в мессенджере увеличится на 10%<br>
__Что делаем в каждой из групп:__ 
+ Контрольная группа без изменений,
+ тестовая группа: сообщение от вк и приветственный стикер с описаниями условий

На каких пользователях тестируем: всех пользователях<br>
__Метрики:__ активность на пользователя в мессенджере, кол-во переходов в сторонние сервисы(вспомогательная)

### Гипотеза 5:  
Если добавить какую-то активность в вк клипы, то кол-во переходов в сторонние сервисы увеличится на 2%<br>

__Что делаем в каждой из групп:__
+ Контрольная группа без изменений,
+ тестовая группа: запускаем рекламу активности от вк клипов<br>

__На каких пользователях тестируем:__ на всех пользователях с мобильного приложения<br>
__Метрики:__ кол-во переходов в сторонние сервисы, кол-во активных пользователей в сторонних сервисах

[Содержание](#содержание)

<hr>

## Практическое задание

Задание 1 Сделайте приоритезацию гипотез из предыдущего урока с помощью ICE

Задание 2.
Составьте шаблон дизайна эксперимента для гипотезы, которая набрала больше всего баллов в практическом задании предыдущего урока

[Содержание](#содержание)

<hr>

[Содержание курса](/ABTesting/README.MD)


